{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME ='frauddetection'\n",
    "import random\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import create_component_from_func\n",
    "from kfp.components import InputPath, OutputPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = \"huanjason/scikit-learn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from minio\n",
    "def data_download(input_data:list, output_dir_path: OutputPath()):\n",
    "    from  minio import Minio\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import urllib3\n",
    "    \n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    file_path1 = os.path.join(output_dir_path, \"Train\" + '.csv')\n",
    "    file_path2 = os.path.join(output_dir_path, \"Train_Inpatientdata\" + '.csv')\n",
    "    file_path3 = os.path.join(output_dir_path, \"Train_Outpatientdata\" + '.csv')\n",
    "    file_path4 = os.path.join(output_dir_path, \"Train_Beneficiarydata\" + '.csv')\n",
    "\n",
    "    minio_client = Minio(\n",
    "    \"172.20.17.71:9000\",\n",
    "    access_key=\"minio\",\n",
    "    secret_key=\"minio123\",\n",
    "    secure=False,\n",
    "    http_client=urllib3.ProxyManager(\n",
    "        \"http://172.20.17.71:9000/\",\n",
    "        timeout=urllib3.Timeout.DEFAULT_TIMEOUT,\n",
    "        cert_reqs=\"CERT_REQUIRED\",\n",
    "        retries=urllib3.Retry(\n",
    "            total=5,\n",
    "            backoff_factor=0.2,\n",
    "            status_forcelist=[500, 502, 503, 504],\n",
    "        ),\n",
    "    ),\n",
    "    )\n",
    "    \n",
    "    obj1 = minio_client.get_object(\"dataset\",input_data[0])\n",
    "    obj2 = minio_client.get_object(\"dataset\",input_data[1])\n",
    "    obj3 = minio_client.get_object(\"dataset\",input_data[2])\n",
    "    obj4 = minio_client.get_object(\"dataset\",input_data[3])    \n",
    "\n",
    "    df1 = pd.read_csv(obj1)\n",
    "    df2 = pd.read_csv(obj2)\n",
    "    df3 = pd.read_csv(obj3)\n",
    "    df4 = pd.read_csv(obj4)\n",
    "\n",
    "    df1.to_csv(file_path1, index = False)\n",
    "    df2.to_csv(file_path2, index = False)\n",
    "    df3.to_csv(file_path3, index = False)\n",
    "    df4.to_csv(file_path4, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(input_dir_path: InputPath(), output_dir_path: OutputPath()):\n",
    "    import os \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    dir_items = os.listdir(input_dir_path)\n",
    "    \n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(output_dir_path, \"final_data\" + '.csv')\n",
    "    \n",
    "    input_file_path1 = input_dir_path + \"/\" + dir_items[0]\n",
    "    input_file_path2 = input_dir_path + \"/\" + dir_items[1]\n",
    "    input_file_path3 = input_dir_path + \"/\" + dir_items[2]\n",
    "    input_file_path4 = input_dir_path + \"/\" + dir_items[3]\n",
    "    \n",
    "    train_target = pd.read_csv(input_file_path1)\n",
    "    train_inpatient = pd.read_csv(input_file_path3)\n",
    "    train_outpatient = pd.read_csv(input_file_path4).iloc[:50000, :]\n",
    "    train_beneficiary = pd.read_csv(input_file_path2)\n",
    "    \n",
    "    final_data = pd.merge(train_inpatient, train_outpatient, left_on = [ col for col in train_outpatient.columns if col in train_inpatient.columns], right_on = [ col for col in train_outpatient.columns if col in train_inpatient.columns], how = 'outer')\n",
    "    final_data = pd.merge(final_data,train_beneficiary,how='inner',on='BeneID' )\n",
    "    final_data = final_data.iloc[:100000, :]\n",
    "\n",
    "    final_data = pd.merge(final_data,train_target,how='outer',on='Provider')\n",
    "    \n",
    "    train_outpatient = pd.merge(train_outpatient,train_target,how='outer',on='Provider')\n",
    "    train_inpatient = pd.merge(train_inpatient,train_target,how='outer',on='Provider')\n",
    "\n",
    "    attendingPhysician_count = final_data['AttendingPhysician'].value_counts().to_dict()\n",
    "    provider_count = final_data['Provider'].value_counts().to_dict()\n",
    "    bene_count = final_data['BeneID'].value_counts().to_dict()\n",
    "\n",
    "    final_data['phycount']=final_data['AttendingPhysician'].map(attendingPhysician_count)\n",
    "    final_data['procount']=final_data['Provider'].map(provider_count)\n",
    "    final_data['benecount']=final_data['BeneID'].map(bene_count)\n",
    "    \n",
    "    train_inpatient['AdmissionDt']= pd.to_datetime(train_inpatient['AdmissionDt'])\n",
    "    train_inpatient['DischargeDt']= pd.to_datetime(train_inpatient['DischargeDt'])\n",
    "    \n",
    "    train_inpatient['numOfDaysAdmitted'] = train_inpatient['DischargeDt'] - train_inpatient['AdmissionDt']\n",
    "    train_inpatient['numOfDaysAdmitted'].replace({pd.NaT: \"0 days\"}, inplace=True)\n",
    "    train_inpatient['numOfDaysAdmitted'] = train_inpatient['numOfDaysAdmitted'].astype(str).map(lambda x: x.split(\" \")[0]).astype('int64')\n",
    "    \n",
    "    attendingPhysician_count = train_inpatient['AttendingPhysician'].value_counts().to_dict()\n",
    "    train_inpatient['phycount']=train_inpatient['AttendingPhysician'].map(attendingPhysician_count)\n",
    "\n",
    "    final_data.drop('ClmProcedureCode_5',axis=1,inplace=True)\n",
    "    final_data.drop('ClmProcedureCode_6',axis=1,inplace=True)\n",
    "    final_data.drop('NoOfMonths_PartACov',axis=1,inplace=True)\n",
    "    final_data.drop('NoOfMonths_PartBCov',axis=1,inplace=True)\n",
    "\n",
    "    colFillna = ['ClmDiagnosisCode_1','ClmDiagnosisCode_2','ClmDiagnosisCode_3','ClmDiagnosisCode_4',\n",
    "                 'ClmDiagnosisCode_5','ClmDiagnosisCode_6','ClmDiagnosisCode_7','ClmDiagnosisCode_8',\n",
    "                 'ClmDiagnosisCode_9','ClmDiagnosisCode_10','ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "                 'ClmProcedureCode_3','ClmProcedureCode_4','DiagnosisGroupCode','ClmAdmitDiagnosisCode']\n",
    "    final_data[colFillna]= final_data[colFillna].replace({np.nan:0})  \n",
    "    \n",
    "    \n",
    "    colFillmode = ['ClmDiagnosisCode_1','ClmDiagnosisCode_2',\n",
    "             'ClmDiagnosisCode_3','ClmDiagnosisCode_4',\n",
    "             'ClmDiagnosisCode_5','ClmDiagnosisCode_6',\n",
    "             'ClmDiagnosisCode_7','ClmDiagnosisCode_8',\n",
    "             'ClmDiagnosisCode_9','ClmDiagnosisCode_10',\n",
    "             'ClmProcedureCode_1','ClmProcedureCode_2',\n",
    "             'ClmProcedureCode_3','ClmProcedureCode_4',\n",
    "             'DiagnosisGroupCode','ClmAdmitDiagnosisCode']\n",
    "\n",
    "    for i in colFillna:\n",
    "        mode = final_data[i].mode()[0]\n",
    "        print(i,'mode :',mode)\n",
    "        final_data[i]=final_data[i].fillna(mode)\n",
    "        \n",
    "    final_data['PotentialFraud'] = final_data['PotentialFraud'].map({'Yes':1,'No':0})\n",
    "    final_data['RenalDiseaseIndicator'] = final_data['RenalDiseaseIndicator'].map({'Y':1,'0':0})\n",
    "    \n",
    "    final_data['ChronicCond_Alzheimer'] = final_data['ChronicCond_Alzheimer'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_Heartfailure'] = final_data['ChronicCond_Heartfailure'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_KidneyDisease'] = final_data['ChronicCond_KidneyDisease'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_Cancer'] = final_data['ChronicCond_Cancer'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_ObstrPulmonary'] = final_data['ChronicCond_ObstrPulmonary'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_Depression'] = final_data['ChronicCond_Depression'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_Diabetes'] = final_data['ChronicCond_Diabetes'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_IschemicHeart'] = final_data['ChronicCond_IschemicHeart'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_Osteoporasis'] = final_data['ChronicCond_Osteoporasis'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_rheumatoidarthritis'] = final_data['ChronicCond_rheumatoidarthritis'].map({2:0,1:1})\n",
    "    final_data['ChronicCond_stroke'] = final_data['ChronicCond_stroke'].map({2:0,1:1})\n",
    "    final_data['Gender'] = final_data['Gender'].map({2:0,1:1})\n",
    "    \n",
    "    bene_count = final_data['BeneID'].value_counts().to_dict()\n",
    "    final_data['BeneCount'] = final_data['BeneID'].map(bene_count)\n",
    "    \n",
    "    pro_count = final_data['Provider'].value_counts().to_dict()\n",
    "    final_data['ProviderCount'] = final_data['Provider'].map(pro_count)\n",
    "    \n",
    "    attphy_count = final_data['AttendingPhysician'].value_counts().to_dict()\n",
    "    final_data['AttendingPhysicianCount'] = final_data['AttendingPhysician'].map(attphy_count)\n",
    "    final_data['AttendingPhysicianCount'] = final_data['AttendingPhysicianCount'].fillna(0)\n",
    "    \n",
    "    mode = final_data['AttendingPhysicianCount'].mode()[0]\n",
    "    final_data['AttendingPhysicianCount']=final_data['AttendingPhysicianCount'].fillna(mode)\n",
    "    df = pd.DataFrame(final_data,columns = ['ClaimStartDt','ClaimEndDt','AdmissionDt','DischargeDt']) \n",
    "    \n",
    "    final_data['AdmissionDt']= pd.to_datetime(final_data['AdmissionDt'])\n",
    "    final_data['DischargeDt']= pd.to_datetime(final_data['DischargeDt'])\n",
    "    final_data['ClaimStartDt']= pd.to_datetime(final_data['ClaimStartDt'])\n",
    "    final_data['ClaimEndDt']= pd.to_datetime(final_data['ClaimEndDt'])\n",
    "\n",
    "    df = pd.DataFrame(final_data,columns = ['ClaimStartDt','ClaimEndDt','AdmissionDt','DischargeDt'])\n",
    "    \n",
    "    final_data['numOfDaysAdmitted'] = final_data['DischargeDt'] - final_data['AdmissionDt']\n",
    "    final_data['numOfDaysAdmitted'].replace({pd.NaT: \"0 days\"}, inplace=True)\n",
    "    final_data['numOfDaysAdmitted'] = final_data['numOfDaysAdmitted'].astype(str).map(lambda x: x.split(\" \")[0]).astype('int64')\n",
    "    \n",
    "    mean = final_data['numOfDaysAdmitted'].mean()\n",
    "    mean = round(mean,1)\n",
    "    final_data['numOfDaysAdmitted']=final_data['numOfDaysAdmitted'].replace({0:mean})\n",
    "    \n",
    "    final_data['numOfDaysForClaim'] = final_data['ClaimEndDt'] - final_data['ClaimStartDt']\n",
    "    final_data['numOfDaysForClaim'].replace({pd.NaT: \"0 days\"}, inplace=True)\n",
    "    final_data['numOfDaysForClaim'] = final_data['numOfDaysForClaim'].astype(str).map(lambda x: x.split(\" \")[0]).astype('int64')\n",
    "    \n",
    "    mean = final_data['numOfDaysForClaim'].mean()\n",
    "    mean = round(mean,1)\n",
    "    final_data['numOfDaysForClaim']=final_data['numOfDaysForClaim'].replace({0:mean})\n",
    "\n",
    "    ip_op_total_amount = final_data['IPAnnualReimbursementAmt'] + final_data['OPAnnualReimbursementAmt']\n",
    "    ip_op_ded_amount = final_data['IPAnnualDeductibleAmt'] + final_data['OPAnnualDeductibleAmt']\n",
    "    ip_op_total_amount = ip_op_total_amount - ip_op_ded_amount\n",
    "    final_data['ip_op_total_amount'] = ip_op_total_amount\n",
    "    \n",
    "    num_of_chronic = final_data['RenalDiseaseIndicator'] + final_data['ChronicCond_Alzheimer'] + \\\n",
    "                    final_data['ChronicCond_Heartfailure'] + final_data['ChronicCond_KidneyDisease'] + \\\n",
    "                    final_data['ChronicCond_Cancer'] + final_data['ChronicCond_ObstrPulmonary'] + \\\n",
    "                    final_data['ChronicCond_Depression'] + final_data['ChronicCond_Diabetes'] + \\\n",
    "                    final_data['ChronicCond_IschemicHeart'] + final_data['ChronicCond_Osteoporasis'] + \\\n",
    "                    final_data['ChronicCond_rheumatoidarthritis'] + final_data['ChronicCond_stroke'] \n",
    "    final_data['num_of_chronic'] = num_of_chronic\n",
    "\n",
    "    num_of_diag_proc = final_data[['ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',\n",
    "       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',\n",
    "       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',\n",
    "       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',\n",
    "       'ClmProcedureCode_3', 'ClmProcedureCode_4', \n",
    "       'DiagnosisGroupCode','ClmAdmitDiagnosisCode']].values\n",
    "    \n",
    "    countnum_of_diag_proc = []\n",
    "    for i in range(len(num_of_diag_proc)):\n",
    "        countnum_of_diag_proc.append(np.count_nonzero(num_of_diag_proc[i]))\n",
    "        \n",
    "    final_data['num_of_diag_proc'] = countnum_of_diag_proc\n",
    "    \n",
    "    num_of_phy = final_data[['AttendingPhysician','OperatingPhysician','OtherPhysician']].fillna(0).values\n",
    "    \n",
    "    countnum_of_phy = []\n",
    "    for i in range(len(num_of_phy)):\n",
    "        countnum_of_phy.append(np.count_nonzero(num_of_phy[i]))\n",
    "        \n",
    "    final_data['num_of_phy'] = countnum_of_phy\n",
    "    \n",
    "    mode = final_data['num_of_phy'].mode()[0]\n",
    "    final_data['num_of_phy']=final_data['num_of_phy'].replace({0:mode})\n",
    "    \n",
    "    diagnosis_code = final_data[['ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',\n",
    "       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',\n",
    "       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',\n",
    "       'ClmDiagnosisCode_10', 'DiagnosisGroupCode','ClmAdmitDiagnosisCode']]\n",
    "    top10 = ['4019','25000','2724','V5869','4011','42731','V5861','2720','2449','4280']\n",
    "    for col in top10:\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_1']==col,1,0)\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_2']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_3']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_4']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_5']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_6']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_7']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_8']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_9']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmDiagnosisCode_10']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['DiagnosisGroupCode']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "        final_data['diagnosis_'+str(col)] = np.where(final_data['ClmAdmitDiagnosisCode']==col,1,np.where(final_data['diagnosis_'+str(col)]==1,1,0 ))\n",
    "    \n",
    "    procedure_code = final_data[['ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4']]\n",
    "    final_data_proc = pd.DataFrame(columns = ['ProCode'])\n",
    "    final_data_proc['ProCode'] = pd.concat([final_data[\"ClmProcedureCode_1\"], \n",
    "                                               final_data[\"ClmProcedureCode_2\"], \n",
    "                                               final_data[\"ClmProcedureCode_3\"], \n",
    "                                               final_data[\"ClmProcedureCode_4\"]], axis=0).dropna()\n",
    "    final_data_proc = pd.DataFrame(columns = ['ProCode'])\n",
    "    final_data_proc['ProCode'] = pd.concat([final_data[\"ClmProcedureCode_1\"], \n",
    "                                               final_data[\"ClmProcedureCode_2\"], \n",
    "                                               final_data[\"ClmProcedureCode_3\"], \n",
    "                                               final_data[\"ClmProcedureCode_4\"]], axis=0).dropna()\n",
    "    \n",
    "\n",
    "    top5 = [4019.0, 9904.0, 2724.0, 8154.0, 66.0]\n",
    "    \n",
    "    for col in top5:\n",
    "        final_data['procedure_'+str(col)] = np.where(final_data['ClmProcedureCode_1']==col,1,0)\n",
    "        final_data['procedure_'+str(col)] = np.where(final_data['ClmProcedureCode_2']==col,1,\\\n",
    "                                       np.where(final_data['procedure_'+str(col)]==1,1,0 ))\n",
    "        final_data['procedure_'+str(col)] = np.where(final_data['ClmProcedureCode_3']==col,1,\\\n",
    "                                       np.where(final_data['procedure_'+str(col)]==1,1,0 ))\n",
    "        final_data['procedure_'+str(col)] = np.where(final_data['ClmProcedureCode_4']==col,1,\\\n",
    "                                       np.where(final_data['procedure_'+str(col)]==1,1,0 ))\n",
    "        \n",
    "\n",
    "    DiagnosisCode_1_count = final_data['ClmDiagnosisCode_1'].value_counts().to_dict()\n",
    "    DiagnosisCode_1_count[0]=0\n",
    "\n",
    "    DiagnosisCode_2_count = final_data['ClmDiagnosisCode_2'].value_counts().to_dict()\n",
    "    DiagnosisCode_2_count[0]=0\n",
    "\n",
    "    DiagnosisCode_3_count = final_data['ClmDiagnosisCode_3'].value_counts().to_dict()\n",
    "    DiagnosisCode_3_count[0]=0\n",
    "\n",
    "    DiagnosisCode_4_count = final_data['ClmDiagnosisCode_4'].value_counts().to_dict()\n",
    "    DiagnosisCode_4_count[0]=0\n",
    "\n",
    "    DiagnosisCode_5_count = final_data['ClmDiagnosisCode_5'].value_counts().to_dict()\n",
    "    DiagnosisCode_5_count[0]=0\n",
    "\n",
    "    DiagnosisCode_6_count = final_data['ClmDiagnosisCode_6'].value_counts().to_dict()\n",
    "    DiagnosisCode_6_count[0]=0\n",
    "\n",
    "    DiagnosisCode_7_count = final_data['ClmDiagnosisCode_7'].value_counts().to_dict()\n",
    "    DiagnosisCode_7_count[0]=0\n",
    "\n",
    "    DiagnosisCode_8_count = final_data['ClmDiagnosisCode_8'].value_counts().to_dict()\n",
    "    DiagnosisCode_8_count[0]=0\n",
    "\n",
    "    DiagnosisCode_9_count = final_data['ClmDiagnosisCode_9'].value_counts().to_dict()\n",
    "    DiagnosisCode_9_count[0]=0\n",
    "\n",
    "    DiagnosisCode_10_count = final_data['ClmDiagnosisCode_10'].value_counts().to_dict()\n",
    "    DiagnosisCode_10_count[0]=0\n",
    "\n",
    "    ClmAdmitDiagnosisCode_count = final_data['ClmAdmitDiagnosisCode'].value_counts().to_dict()\n",
    "    ClmAdmitDiagnosisCode_count[0]=0\n",
    "\n",
    "    DiagnosisGroupCode_count = final_data['DiagnosisGroupCode'].value_counts().to_dict()\n",
    "    DiagnosisGroupCode_count[0]=0\n",
    "    \n",
    "    \n",
    "    DiagnosisCode_1_count = final_data['ClmDiagnosisCode_1'].value_counts().to_dict()\n",
    "    DiagnosisCode_2_count = final_data['ClmDiagnosisCode_2'].value_counts().to_dict()\n",
    "    DiagnosisCode_3_count = final_data['ClmDiagnosisCode_3'].value_counts().to_dict()\n",
    "    DiagnosisCode_4_count = final_data['ClmDiagnosisCode_4'].value_counts().to_dict()\n",
    "    DiagnosisCode_5_count = final_data['ClmDiagnosisCode_5'].value_counts().to_dict()\n",
    "    DiagnosisCode_6_count = final_data['ClmDiagnosisCode_6'].value_counts().to_dict()\n",
    "    DiagnosisCode_7_count = final_data['ClmDiagnosisCode_7'].value_counts().to_dict()\n",
    "    DiagnosisCode_8_count = final_data['ClmDiagnosisCode_8'].value_counts().to_dict()\n",
    "    DiagnosisCode_9_count = final_data['ClmDiagnosisCode_9'].value_counts().to_dict()\n",
    "    DiagnosisCode_10_count = final_data['ClmDiagnosisCode_10'].value_counts().to_dict()\n",
    "    ClmAdmitDiagnosisCode_count = final_data['ClmAdmitDiagnosisCode'].value_counts().to_dict()\n",
    "    DiagnosisGroupCode_count = final_data['DiagnosisGroupCode'].value_counts().to_dict()\n",
    "\n",
    "    final_data['DiagnosisCode_1_count'] = final_data['ClmDiagnosisCode_1'].map(DiagnosisCode_1_count)\n",
    "    final_data['DiagnosisCode_2_count'] = final_data['ClmDiagnosisCode_2'].map(DiagnosisCode_2_count)\n",
    "    final_data['DiagnosisCode_3_count'] = final_data['ClmDiagnosisCode_3'].map(DiagnosisCode_3_count)\n",
    "    final_data['DiagnosisCode_4_count'] = final_data['ClmDiagnosisCode_4'].map(DiagnosisCode_4_count)\n",
    "    final_data['DiagnosisCode_5_count'] = final_data['ClmDiagnosisCode_5'].map(DiagnosisCode_5_count)\n",
    "    final_data['DiagnosisCode_6_count'] = final_data['ClmDiagnosisCode_6'].map(DiagnosisCode_6_count)\n",
    "    final_data['DiagnosisCode_7_count'] = final_data['ClmDiagnosisCode_7'].map(DiagnosisCode_7_count)\n",
    "    final_data['DiagnosisCode_8_count'] = final_data['ClmDiagnosisCode_8'].map(DiagnosisCode_8_count)\n",
    "    final_data['DiagnosisCode_9_count'] = final_data['ClmDiagnosisCode_9'].map(DiagnosisCode_9_count)\n",
    "    final_data['DiagnosisCode_10_count'] = final_data['ClmDiagnosisCode_10'].map(DiagnosisCode_10_count)\n",
    "    final_data['ClmAdmitDiagnosisCode_count'] = final_data['ClmAdmitDiagnosisCode'].map(ClmAdmitDiagnosisCode_count)\n",
    "    final_data['DiagnosisGroupCode_count'] = final_data['DiagnosisGroupCode'].map(DiagnosisGroupCode_count)\n",
    "    \n",
    "    final_data['DeductibleAmtPaid']= final_data['DeductibleAmtPaid'].replace({np.nan:0})\n",
    "    mean = final_data['DeductibleAmtPaid'].mean()\n",
    "    mean = round(mean,0)\n",
    "    final_data['DeductibleAmtPaid']=final_data['DeductibleAmtPaid'].replace({np.nan:mean})\n",
    "\n",
    "    final_data = final_data.drop(['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider','AttendingPhysician', 'OperatingPhysician',\n",
    "       'OtherPhysician', 'AdmissionDt','ClmAdmitDiagnosisCode','DischargeDt', 'DiagnosisGroupCode',\n",
    "       'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',\n",
    "       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',\n",
    "       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',\n",
    "       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',\n",
    "       'ClmProcedureCode_3', 'ClmProcedureCode_4','DOB', 'DOD'],axis=1)\n",
    "    \n",
    "    final_data.to_csv(file_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(input_dir_path: InputPath(), output_dir_path: OutputPath()):\n",
    "    import os \n",
    "    import json\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    import seaborn as sns\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.linear_model import LogisticRegression \n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import roc_curve, f1_score, confusion_matrix\n",
    "        \n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(output_dir_path, \"lr_model\" + '.pkl')\n",
    "    \n",
    "    final_data = pd.read_csv(input_dir_path + \"/\" + 'final_data' + '.csv')\n",
    "    final_data = final_data.dropna().reset_index()\n",
    "    \n",
    "    Y = final_data['PotentialFraud']\n",
    "    X = final_data.drop('PotentialFraud',axis=1)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, stratify = Y)\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    col_to_nor = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'Race',\n",
    "       'State', 'County', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
    "       'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'BeneCount',\n",
    "       'ProviderCount', 'AttendingPhysicianCount', 'numOfDaysAdmitted',\n",
    "       'numOfDaysForClaim', 'ip_op_total_amount', 'num_of_chronic',\n",
    "       'num_of_diag_proc', 'num_of_phy', 'DiagnosisCode_1_count', 'DiagnosisCode_2_count',\n",
    "       'DiagnosisCode_3_count', 'DiagnosisCode_4_count',\n",
    "       'DiagnosisCode_5_count', 'DiagnosisCode_6_count',\n",
    "       'DiagnosisCode_7_count', 'DiagnosisCode_8_count',\n",
    "       'DiagnosisCode_9_count', 'DiagnosisCode_10_count',\n",
    "       'ClmAdmitDiagnosisCode_count', 'DiagnosisGroupCode_count']\n",
    "\n",
    "    X_train.loc[:,col_to_nor] = min_max_scaler.fit_transform(X_train[col_to_nor])\n",
    "    X_test.loc[:,col_to_nor] = min_max_scaler.fit_transform(X_test[col_to_nor])\n",
    "    \n",
    "    lr = LogisticRegression(C=5 , penalty='l2')\n",
    "    lr.fit(X_train,Y_train)\n",
    "    \n",
    "    print('accuracy on test data:',lr.score(X_test,Y_test))\n",
    "    \n",
    "    pickle.dump(lr, open(file_path, 'wb'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(input_dir_path: InputPath(),  output_dir_path: OutputPath()):\n",
    "    import os \n",
    "    import json\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    import seaborn as sns\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import roc_curve, f1_score, confusion_matrix\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    file_path = os.path.join(output_dir_path, \"dt_model\" + '.pkl')\n",
    "    \n",
    "    final_data = pd.read_csv(input_dir_path + \"/\" + 'final_data' + '.csv')\n",
    "    final_data = final_data.dropna().reset_index()\n",
    "    \n",
    "    Y = final_data['PotentialFraud']\n",
    "    X = final_data.drop('PotentialFraud',axis=1)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, stratify = Y)\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    col_to_nor = ['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'Race',\n",
    "       'State', 'County', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
    "       'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'BeneCount',\n",
    "       'ProviderCount', 'AttendingPhysicianCount', 'numOfDaysAdmitted',\n",
    "       'numOfDaysForClaim', 'ip_op_total_amount', 'num_of_chronic',\n",
    "       'num_of_diag_proc', 'num_of_phy', 'DiagnosisCode_1_count', 'DiagnosisCode_2_count',\n",
    "       'DiagnosisCode_3_count', 'DiagnosisCode_4_count',\n",
    "       'DiagnosisCode_5_count', 'DiagnosisCode_6_count',\n",
    "       'DiagnosisCode_7_count', 'DiagnosisCode_8_count',\n",
    "       'DiagnosisCode_9_count', 'DiagnosisCode_10_count',\n",
    "       'ClmAdmitDiagnosisCode_count', 'DiagnosisGroupCode_count']\n",
    "\n",
    "    X_train.loc[:,col_to_nor] = min_max_scaler.fit_transform(X_train[col_to_nor])\n",
    "    X_test.loc[:,col_to_nor] = min_max_scaler.fit_transform(X_test[col_to_nor])\n",
    "    \n",
    "    params = {\"max_depth\":250,\"min_samples_split\":70,\"criterion\":'gini'}\n",
    "    dt = DecisionTreeClassifier(max_depth=params[\"max_depth\"],min_samples_split=params[\"min_samples_split\"],criterion=params[\"criterion\"])\n",
    "    dt.fit(X_train,Y_train)\n",
    "    \n",
    "    print('accuracy on test data:',dt.score(X_test,Y_test))\n",
    "    \n",
    "    pickle.dump(dt, open(file_path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the python function to component\n",
    "download_data_opp = create_component_from_func(data_download,base_image=BASE_IMAGE, packages_to_install=['minio', 'pandas'])\n",
    "process_data_opp = create_component_from_func(process_data,base_image=BASE_IMAGE, packages_to_install=['minio', 'pandas'])\n",
    "lr_building_opp = create_component_from_func(logistic_regression,base_image=BASE_IMAGE, packages_to_install=['minio', 'pandas'])\n",
    "dt_building_opp = create_component_from_func(decision_tree,base_image=BASE_IMAGE, packages_to_install=['minio', 'pandas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name='model-training-pipeline')\n",
    "def model_pipeline(data=[\"Train.csv\",\"Train_Inpatientdata.csv\",\"Train_Outpatientdata.csv\",\"Train_Beneficiarydata.csv\"]):\n",
    "    download_data_task = download_data_opp(data)    \n",
    "    eda_opp_task = process_data_opp(input_dir=download_data_task.output)\n",
    "    lr_opp_task = lr_building_opp(input_dir=eda_opp_task.output)\n",
    "    dt_opp_task = dt_building_opp( input_dir=eda_opp_task.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(model_pipeline, 'model-training-pipeline.yaml')\n",
    "HOST = 'https://kubeflow-workos-slvr.anthem.com'    \n",
    "namespace = \"harikrishna-kantipudi\"\n",
    "session_cookie = \"MTY0MzYxNzg2OXxOd3dBTkZRM1JWQTNSelkxVEROQ1JWcFdUVTFNTlROS1MxVkxVMUZGVURKSFFWWlFTazQxTTFWWVVFaEdUa3BZVlU1UFNWRk1UVkU9fFoyKCgVjNiyE7B35bl5xiqntpFalMBqJqfCnxzEC8yt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://kubeflow-workos-slvr.anthem.com/pipeline/#/experiments/details/78236bfa-c2a4-4bd3-82ec-db07e45e4c3e\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://kubeflow-workos-slvr.anthem.com/pipeline/#/experiments/details/78236bfa-c2a4-4bd3-82ec-db07e45e4c3e\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://kubeflow-workos-slvr.anthem.com/pipeline/#/runs/details/ddc9fc33-e2a0-4361-9904-6913e59298be\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=ddc9fc33-e2a0-4361-9904-6913e59298be)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = kfp.Client(\n",
    "    host=f\"{HOST}/pipeline\",\n",
    "    cookies=f\"authservice_session={session_cookie}\",\n",
    "    namespace=namespace, ssl_ca_cert=\"./root.pem\")\n",
    "\n",
    "experiment = client.create_experiment(name=EXPERIMENT_NAME,namespace=namespace)\n",
    "client.create_run_from_pipeline_func(pipeline_func=model_pipeline, arguments={}, experiment_name=EXPERIMENT_NAME,\n",
    "                                     namespace=namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "161277634314.dkr.ecr.us-east-2.amazonaws.com/jupyterlab-base@sha256:f86659eaf1bfec875ff5f3a96aa240eba98cc43ec585453d98e6e68c4a943123",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
